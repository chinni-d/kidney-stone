{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train the MLP Model (Save this as train_model.py)\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "data_dir = 'C:/Users/darap/Downloads/kidney_stones/kidney_stones/dataset'\n",
    "categories = ['stone', 'no_stone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "img_size = (64, 64)  # Resize all images to 64x64\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in categories:\n",
    "    class_label = categories.index(category)\n",
    "    path = os.path.join(data_dir, category)\n",
    "    for img_file in os.listdir(path):\n",
    "        try:\n",
    "            # Open image and convert to RGB\n",
    "            img = Image.open(os.path.join(path, img_file)).convert('RGB')\n",
    "            # Resize image\n",
    "            img = img.resize(img_size)\n",
    "            # Convert to numpy array\n",
    "            img_array = np.array(img)\n",
    "            # Append to data list\n",
    "            data.append(img_array)\n",
    "            labels.append(class_label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to numpy arrays\n",
    "data = np.array(data) / 255.0  # Normalize pixel values to [0, 1]\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build MLP Model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(img_size[0], img_size[1], 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Output layer with 2 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9071 - loss: 0.2181 - val_accuracy: 0.9835 - val_loss: 0.0536\n",
      "Epoch 2/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0357 - val_accuracy: 0.9825 - val_loss: 0.0649\n",
      "Epoch 3/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0124 - val_accuracy: 0.9920 - val_loss: 0.0365\n",
      "Epoch 4/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0104 - val_accuracy: 0.9931 - val_loss: 0.0294\n",
      "Epoch 5/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0086 - val_accuracy: 0.9931 - val_loss: 0.0406\n",
      "Epoch 6/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9602 - val_loss: 0.3179\n",
      "Epoch 7/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.0259 - val_accuracy: 0.9915 - val_loss: 0.0529\n",
      "Epoch 8/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0096 - val_accuracy: 0.9979 - val_loss: 0.0355\n",
      "Epoch 9/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.9793 - val_loss: 0.0983\n",
      "Epoch 10/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9950 - loss: 0.0135 - val_accuracy: 0.9968 - val_loss: 0.0336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2456c7257f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved at './model/mlp_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "model.save('./model/mlp_model.h5')\n",
    "print(\"Model trained and saved at './model/mlp_model.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
